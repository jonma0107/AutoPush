### ğŸ§  Resumen del Proyecto: ZenML + FastAPI + IA Generativa

Este proyecto tiene como objetivo enseÃ±ar cÃ³mo construir **sistemas backend robustos** utilizando **FastAPI** para soportar pipelines **MLOps escalables** y **aplicaciones impulsadas por IA**, especÃ­ficamente con enfoque en **IA generativa**.

---

### ğŸ¯ Objetivo General
Aprender a construir sistemas backend que:
- Integren modelos de IA entrenados.
- Utilicen pipelines reproducibles para MLOps.
- Se desplieguen en producciÃ³n con monitorizaciÃ³n.
- Aumenten su capacidad con tecnologÃ­as como **BigQuery** y nativas de la nube.

---

### ğŸ“š Ruta de Aprendizaje

1. **Fundamentos de FastAPI**
   - DocumentaciÃ³n oficial: [FastAPI](https://fastapi.tiangolo.com/)
   - Curso recomendado: [FastAPI Crash Course - YouTube](https://www.youtube.com/watch?v=0sOvCWFmrtA)

2. **Conceptos de MLOps**
   - Entender quÃ© es MLOps y su ciclo de vida.
   - Curso prÃ¡ctico: [MLOps with MLflow and Azure ML - Microsoft](https://learn.microsoft.com/en-us/training/modules/mlops-deployment/)

3. **ZenML**
   - Uso de ZenML para pipelines de ML: `ingest`, `train`, `evaluate`.
   - DocumentaciÃ³n: [https://docs.zenml.io](https://docs.zenml.io)

4. **BigQuery y alternativas**
   - BigQuery es un **almacenamiento y procesamiento analÃ­tico de datos a gran escala** de Google Cloud.
   - Alternativas:
     - Amazon Redshift (AWS)
     - Snowflake
     - Azure Synapse
     - PostgreSQL + Pandas para proyectos pequeÃ±os/medianos

5. **IntegraciÃ³n con modelos de IA Generativa**
   - OpenAI, HuggingFace Transformers, LangChain.
   - Cargar modelos de texto o imagen y desplegarlos mediante FastAPI.

6. **Despliegue en producciÃ³n**
   - Docker + Uvicorn + Nginx
   - MonitorizaciÃ³n con Prometheus/Grafana
   - Deploy en GCP, AWS o Render.com

---

### ğŸ’» Ejemplo de AplicaciÃ³n Backend (Paso a Paso)

#### Estructura del Proyecto
```
project/
â”œâ”€â”€ main.py               # API con FastAPI
â”œâ”€â”€ run_pipeline.py       # Ejecuta el pipeline ZenML
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ ingest.py         # Carga datos
â”‚   â”œâ”€â”€ train.py          # Entrena modelo
â”‚   â””â”€â”€ predict.py        # Realiza predicciÃ³n
â”œâ”€â”€ model/
â”‚   â””â”€â”€ model.pkl         # Modelo entrenado
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ .gitignore
```

#### Flujo de trabajo
1. Se ejecuta `run_pipeline.py` que:
   - Carga los datos (diabetes dataset o texto generativo).
   - Entrena un modelo (regresiÃ³n o modelo generativo simple).
   - Guarda el modelo.

2. Se lanza la API con `main.py` para recibir peticiones:
   ```bash
   uvicorn main:app --reload
   ```

3. Se puede consultar la documentaciÃ³n en `http://localhost:8000/docs` y enviar peticiones POST al endpoint `/predict` con los datos.

---

### ğŸ”® Â¿QuÃ© podrÃ­as construir despuÃ©s?
- Clasificador de sentimientos de reseÃ±as de productos.
- Generador de texto con OpenAI/GPT desde FastAPI.
- AnÃ¡lisis de grandes volÃºmenes de texto con BigQuery + FastAPI + LangChain.

## Clasificador de Sentimientos de ReseÃ±as de Productos con FastAPI + ZenML

### ğŸ¯ Objetivo
Construir una aplicaciÃ³n backend robusta con **FastAPI** y **ZenML** que clasifique reseÃ±as de productos como **positivas** o **negativas**, integrando todo en un pipeline de MLOps simple.

---

### ğŸ“¦ Estructura del Proyecto
```
sentiment_classifier/
â”œâ”€â”€ main.py                # API FastAPI
â”œâ”€â”€ run_pipeline.py        # Ejecuta el pipeline ZenML
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ ingest.py          # Carga y preprocesamiento de datos
â”‚   â”œâ”€â”€ train.py           # Entrenamiento del modelo
â”‚   â””â”€â”€ predict.py         # Paso para predecir
â”œâ”€â”€ model/
â”‚   â””â”€â”€ model.pkl          # Modelo entrenado guardado
â”œâ”€â”€ requirements.txt       # LibrerÃ­as del proyecto
â”œâ”€â”€ Dockerfile             # Contenedor opcional
â””â”€â”€ .gitignore             # Archivos ignorados por Git
```

---

### ğŸ”„ Pipeline con ZenML
1. `ingest.py`: carga dataset simple de reseÃ±as (sklearn `load_files` o CSV local).
2. `train.py`: entrena modelo con `TfidfVectorizer` + `LogisticRegression` o `MultinomialNB`.
3. `predict.py`: carga modelo y permite predicciÃ³n desde FastAPI.

---

### ğŸ§ª Dataset PequeÃ±o
Usaremos un dataset pequeÃ±o como `sklearn.datasets.load_files` con reseÃ±as etiquetadas en dos carpetas:
```
data/
â”œâ”€â”€ pos/
â”‚   â”œâ”€â”€ 0.txt  # buena reseÃ±a
â”œâ”€â”€ neg/
â”‚   â”œâ”€â”€ 1.txt  # mala reseÃ±a
```
Puedes tener 10-20 archivos por clase para pruebas locales.

---

### ğŸ–¥ï¸ Endpoint FastAPI `/predict`
- Entrada: `{"review": "this product is amazing"}`
- Salida: `{"sentiment": "positive"}`

---

### âœ… `.gitignore`
```
__pycache__/
*.pyc
*.pkl
.env
.venv/
.idea/
*.sqlite3
.DS_Store
*.log
```

---

### ğŸ“Œ Comandos Iniciales
```bash
git init
git add .
git commit -m "Initial commit: FastAPI + ZenML backend for sentiment classifier"
```

---

### âœ… CÃ³digo del Proyecto

#### `requirements.txt`
```
fastapi
uvicorn
scikit-learn
pydantic
joblib
zenml[server]
```

#### `main.py`
```python
from fastapi import FastAPI
from pydantic import BaseModel
import joblib

app = FastAPI()
model = joblib.load("model/model.pkl")

class ReviewRequest(BaseModel):
    review: str

@app.post("/predict")
def predict_sentiment(request: ReviewRequest):
    prediction = model.predict([request.review])[0]
    return {"sentiment": prediction}
```

#### `run_pipeline.py`
```python
from zenml.pipelines import pipeline
from pipelines.ingest import ingest_data
from pipelines.train import train_model

@pipeline
def sentiment_pipeline():
    X_train, X_test, y_train, y_test = ingest_data()
    train_model(X_train, X_test, y_train, y_test)

if __name__ == '__main__':
    sentiment_pipeline()()
```

#### `pipelines/ingest.py`
```python
from sklearn.datasets import load_files
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer


def ingest_data():
    data = load_files("data", categories=['pos', 'neg'])
    X_train, X_test, y_train, y_test = train_test_split(
        data.data, data.target, test_size=0.2, random_state=42
    )
    return X_train, X_test, y_train, y_test
```

#### `pipelines/train.py`
```python
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import joblib


def train_model(X_train, X_test, y_train, y_test):
    pipe = Pipeline([
        ("tfidf", TfidfVectorizer()),
        ("clf", LogisticRegression())
    ])
    pipe.fit(X_train, y_train)
    joblib.dump(pipe, "model/model.pkl")
```

#### `pipelines/predict.py`
```python
import joblib

def predict_review(text):
    model = joblib.load("model/model.pkl")
    return model.predict([text])[0]
```

#### `Dockerfile`
```
FROM python:3.9

WORKDIR /app
COPY . .

RUN pip install --no-cache-dir -r requirements.txt

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

Ya tienes un proyecto completo y funcional con FastAPI + ZenML listo para clonar, ejecutar y probar ğŸ§ âš™ï¸. Â¿Te gustarÃ­a que lo suba como repositorio de GitHub o necesitas ayuda para hacerlo tÃº mismo?


